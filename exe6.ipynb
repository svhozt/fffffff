{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c16609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svhozt\\AppData\\Local\\Temp/ipykernel_19784/1798505664.py:21: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data = data.fillna(data.mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day  hour  PM_City1  PM_Dongsihuan  PM_Nongzhanguan  \\\n",
      "0  2010      1    1     0   0.11856      93.723659        89.953275   \n",
      "1  2010      1    1     1   0.11856      93.723659        89.953275   \n",
      "2  2010      1    1     2   0.11856      93.723659        89.953275   \n",
      "3  2010      1    1     3   0.11856      93.723659        89.953275   \n",
      "4  2010      1    1     4   0.11856      93.723659        89.953275   \n",
      "\n",
      "   PM_US Post      DEWP      HUMI      PRES      TEMP  PM_City2  PM_Shahepu  \\\n",
      "0     0.07618  0.995113  0.994356  0.647887  0.242857  0.125529   84.143639   \n",
      "1     0.07618  0.995113  0.994752  0.633803  0.228571  0.125529   84.143639   \n",
      "2     0.07618  0.995113  0.994356  0.619718  0.242857  0.125529   84.143639   \n",
      "3     0.07618  0.995113  0.995544  0.619718  0.200000  0.125529   84.143639   \n",
      "4     0.07618  0.995213  0.995148  0.605634  0.228571  0.125529   84.143639   \n",
      "\n",
      "   PM_City3  PM_5th Middle School  PM_City4   PM_Xuhui  PM_City5  PM_Xiaoheyan  \n",
      "0  0.102621             53.542269  0.090731  60.280218  0.073693     77.535936  \n",
      "1  0.102621             53.542269  0.090731  60.280218  0.073693     77.535936  \n",
      "2  0.102621             53.542269  0.090731  60.280218  0.073693     77.535936  \n",
      "3  0.102621             53.542269  0.090731  60.280218  0.073693     77.535936  \n",
      "4  0.102621             53.542269  0.090731  60.280218  0.073693     77.535936  \n",
      " best algorithm using cross Mean Squared Error \n",
      "Linear Regression MSE: 0.00016602239481518062\n",
      "Decision Tree MSE: 0.00010543624845930498\n",
      "Neural Network MSE: 0.030643123146158035\n",
      "Decision Tree is the best algorithm\n",
      " best algorithm using cross validation method \n",
      "Linear Regression MSE: 0.009699711438204747\n",
      "Decision Tree MSE: 0.0011780687499833888\n",
      "Neural Network MSE: 29.163789016068357\n",
      "Decision Tree is the best algorithm\n",
      "Best hyperparameters: {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 6}\n",
      "[[0.11890065 0.12341964 0.10265423 0.0894153  0.07364702]\n",
      " [0.11890065 0.12341964 0.10265423 0.0894153  0.07364702]\n",
      " [0.11890065 0.12341964 0.10265423 0.0894153  0.07364702]\n",
      " ...\n",
      " [0.11890065 0.12341964 0.10265423 0.0894153  0.07364702]\n",
      " [0.11890065 0.12341964 0.10265423 0.0894153  0.07364702]\n",
      " [0.11890065 0.12341964 0.10265423 0.0894153  0.07364702]]\n",
      "Decision Tree MSE: 0.00034976101042934286\n",
      "Enter the city (0 for Beijing, 1 for Chengdu, 2 for Guangzhou, 3 for Shanghai, 4 for Shenyang): 0\n",
      "Enter the day: 1\n",
      "Enter the month: 1\n",
      "Enter the year: 2010\n",
      "Enter the hour: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 9 features, but DecisionTreeRegressor is expecting 15 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19784/1798505664.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[0mcity_encoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m \u001b[0mpm25_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted PM2.5 concentration: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpm25_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \"\"\"\n\u001b[0;32m    441\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[0;32m    408\u001b[0m                                     reset=False)\n\u001b[0;32m    409\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 9 features, but DecisionTreeRegressor is expecting 15 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load data for all five cities\n",
    "city1 = pd.read_csv('BeijingPMtrain.csv')\n",
    "city2 = pd.read_csv('ChengduPMtrain.csv')\n",
    "city3 = pd.read_csv('GuangzhouPMtrain.csv')\n",
    "city4 = pd.read_csv('ShanghaiPMtrain.csv')\n",
    "city5 = pd.read_csv('ShenyangPMtrain.csv')\n",
    "\n",
    "# Combine data for all five cities\n",
    "data = pd.concat([city1, city2, city3, city4, city5])\n",
    "\n",
    "# Handling missing values\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "# Renaming columns\n",
    "data = data.rename(columns={'PM_Dongsi': 'PM_City1', \n",
    "                           'PM_Caotangsi': 'PM_City2', \n",
    "                           'PM_City Station': 'PM_City3', \n",
    "                           'PM_Jingan': 'PM_City4', \n",
    "                           'PM_Taiyuanjie': 'PM_City5'})\n",
    "\n",
    "# Removing unnecessary columns\n",
    "data = data.drop(['No','season','cbwd','Iws','precipitation','Iprec'], axis=1)\n",
    "\n",
    "# Normalizing the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data[['PM_City1', 'PM_City2', 'PM_City3', 'PM_City4', 'PM_City5', 'PM_US Post', 'DEWP', 'HUMI', 'PRES', 'TEMP']] = scaler.fit_transform(data[['PM_City1', 'PM_City2', 'PM_City3', 'PM_City4', 'PM_City5', 'PM_US Post', 'DEWP', 'HUMI', 'PRES', 'TEMP']])\n",
    "\n",
    "\n",
    "X = data.drop(['PM_City1', 'PM_City2', 'PM_City3', 'PM_City4', 'PM_City5'], axis=1)\n",
    "y = data[['PM_City1', 'PM_City2', 'PM_City3', 'PM_City4', 'PM_City5']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# best algorithm using Mean Squared Error\n",
    "\n",
    "# Linear Regression\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "lin_mse_cross = -1*cross_val_score(reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "lin_mse_mean = np.mean(lin_mse_cross)\n",
    "\n",
    "# Decision Tree\n",
    "reg = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "dt_mse_cross = -1*cross_val_score(reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "dt_mse_mean = np.mean(dt_mse_cross)\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "reg = MLPRegressor().fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "nn_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "nn_mse_cross = -1*cross_val_score(reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "nn_mse_mean = np.mean(nn_mse_cross)\n",
    "\n",
    "print(\" best algorithm using cross Mean Squared Error \")\n",
    "\n",
    "# Compare mean squared errors\n",
    "print(\"Linear Regression MSE:\", lin_mse)\n",
    "print(\"Decision Tree MSE:\", dt_mse)\n",
    "print(\"Neural Network MSE:\", nn_mse)\n",
    "\n",
    "# Find the best algorithm\n",
    "best_algorithm = min(lin_mse, dt_mse, nn_mse)\n",
    "\n",
    "if best_algorithm == lin_mse:\n",
    "    print(\"Linear Regression is the best algorithm\")\n",
    "elif best_algorithm == dt_mse:\n",
    "    print(\"Decision Tree is the best algorithm\")\n",
    "else:\n",
    "    print(\"Neural Network is the best algorithm\")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# best algorithm using cross validation method \n",
    "\n",
    "print(\" best algorithm using cross validation method \")\n",
    "\n",
    "print(\"Linear Regression MSE:\", lin_mse_mean)\n",
    "print(\"Decision Tree MSE:\", dt_mse_mean)\n",
    "print(\"Neural Network MSE:\", nn_mse_mean)\n",
    "\n",
    "# Find the best algorithm\n",
    "best_algorithm = min(lin_mse_mean, dt_mse_mean, nn_mse_mean)\n",
    "\n",
    "if best_algorithm == lin_mse_mean:\n",
    "    print(\"Linear Regression is the best algorithm\")\n",
    "elif best_algorithm == dt_mse_mean:\n",
    "    print(\"Decision Tree is the best algorithm\")\n",
    "else:\n",
    "    print(\"Neural Network is the best algorithm\")\n",
    "    \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'max_depth': [2, 4, 6, 8, 10],\n",
    "              'min_samples_split': [2, 4, 6, 8, 10],\n",
    "              'min_samples_leaf': [1, 2, 3, 4, 5]}\n",
    "\n",
    "# Create the decision tree model\n",
    "reg = DecisionTreeRegressor()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best set of hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "reg = DecisionTreeRegressor(max_depth=4, min_samples_leaf=3, min_samples_split=6)\n",
    "\n",
    "# Fit the model to the training data\n",
    "reg.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = reg.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate mean squared error\n",
    "dt_mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Decision Tree MSE:\", dt_mse)\n",
    "\n",
    "# Making predictions\n",
    "city = int(input(\"Enter the city (0 for Beijing, 1 for Chengdu, 2 for Guangzhou, 3 for Shanghai, 4 for Shenyang): \"))\n",
    "day = int(input(\"Enter the day: \"))\n",
    "month = int(input(\"Enter the month: \"))\n",
    "year = int(input(\"Enter the year: \"))\n",
    "hour = int(input(\"Enter the hour: \"))\n",
    "city_encoded = [0,0,0,0,0]\n",
    "city_encoded[city] = 1\n",
    "\n",
    "pm25_pred = reg.predict([np.concatenate((city_encoded, [day, month, year, hour]))])\n",
    "print(\"Predicted PM2.5 concentration: \", pm25_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16107fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = df_pc2\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop(\"pm2.5\", axis=1)\n",
    "y = df[\"pm2.5\"]\n",
    "\n",
    "# Reshape the target data into a 3D format for the LSTM model\n",
    "y = np.array(y).reshape((len(y), 1))\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(None, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Perform time series cross-validation to evaluate the LSTM model\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "scores = []\n",
    "for train_index, test_index in tscv.split(y):\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(y_train, y_train, epochs=10, batch_size=1, verbose=0)\n",
    "    y_pred = model.predict(y_test)\n",
    "    score = mean_absolute_error(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Print the mean cross-validation score\n",
    "print(\"Mean Cross-Validation Score:\", np.mean(scores))\n",
    "\n",
    "# Train the LSTM model on the entire dataset\n",
    "model.fit(y, y, epochs=10, batch_size=1, verbose=0)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "y_pred = model.predict(y)\n",
    "\n",
    "# Evaluate the model using mean absolute error and mean squared error\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425eaf94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
